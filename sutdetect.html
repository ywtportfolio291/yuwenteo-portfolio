<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>SUTDetect - HTX </title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    html {
      scroll-behavior: smooth;
    }
  
    .active-link {
      font-weight: 600;
      color: #1e3a8a; /* blue-900 */
    }
    .hidden {
  display: none;
}
.standard-img {
    width: 100%;
    max-width: 60rem; /* ~ max-w-xl */
    border-radius: 0.5rem; /* rounded-lg */
    box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1), 0 4px 6px -4px rgba(0,0,0,0.1); /* shadow-md */
  }

  </style>  
</head>
<body class="bg-white text-gray-900 tracking-[-0.02em]">

  <!-- Navbar -->
  <nav class="sticky top-0 z-50 bg-white flex items-center justify-between px-8 py-4 border-b shadow-sm">
    <a href="index.html" class="text-lg font-semibold text-blue-700 hover:text-blue-900 transition-colors duration-300 tracking-[-0.02em]">
      ← Back to Main Page
    </a>

    <!-- Right: Links -->
    <div class="flex gap-6">
      <a href="https://www.linkedin.com/in/teo-yu-wen-bb9573203/"
         class="text-lg font-medium text-gray-600 hover:text-gray-900 transition-colors duration-300 flex items-center gap-1 tracking-[-0.02em]"
         target="_blank" rel="noopener noreferrer">
        LinkedIn
        <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
          <path stroke-linecap="round" stroke-linejoin="round" d="M9 15l6-6m0 0h-4m4 0v4" />
        </svg>
      </a>

      <a href="./assets/Teo Yu Wen Resume 2025 v2.pdf"
         class="text-lg font-medium text-gray-600 hover:text-gray-900 transition-colors duration-300 flex items-center gap-1 tracking-[-0.02em]"
         target="_blank" rel="noopener noreferrer">
        Resume
        <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
          <path stroke-linecap="round" stroke-linejoin="round" d="M9 15l6-6m0 0h-4m4 0v4" />
        </svg>
      </a>
    </div>
  </nav>

  <!-- Image Placeholder -->
  <div class="w-full h-80 bg-gradient-to-r from-green-200 via-yellow-100 to-green-200 flex items-center justify-center">
    <span class="text-xl text-gray-500 tracking-[-0.02em]">[ Insert Image Here ]</span>
  </div>

    <!-- Container Wrapper -->
    <div class="w-full px-6 md:px-8 flex justify-center">
      <div class="max-w-screen-lg w-full flex mt-12">

  <!-- Main Layout with Sidebar -->
    <!-- Sticky Sidebar -->
    <aside class="hidden md:block w-48 pr-8 sticky top-20 self-start">
      <nav class="space-y-4 text-gray-400 text-sm tracking-[-0.02em]">
        <a href="#summary" class="nav-link block hover:text-blue-900 tracking-[-0.02em]">Summary</a>
        <a href="#introduction" class="nav-link block hover:text-blue-900 tracking-[-0.02em]">Introduction</a>
        <a href="#discovery" class="nav-link block hover:text-blue-900 tracking-[-0.02em]">Discovery</a>
        <a href="#mvp" class="nav-link block hover:text-blue-900 tracking-[-0.02em]">Building MVP</a>
        <a href="#impact" class="nav-link block hover:text-blue-900 tracking-[-0.02em]">Impact</a>
        <a href="#learnings" class="nav-link block hover:text-blue-900 tracking-[-0.02em]">Next Steps</a>
      </nav>
    </aside>

    <!-- Main Content -->
    <section class="flex-1 space-y-16">

      <!-- Summary -->
<div id="summary">
  <p class="text-gray-500 text-sm font-medium tracking-[-0.02em]">✴ '25, HTX </p>
  <h1 class="text-3xl md:text-4xl font-bold mt-1 text-blue-900 tracking-[-0.02em]">
    HTX, SUTDetect - A research and software project
  </h1>

  <p class="mt-4 text-gray-700 text-lg tracking-[-0.02em]">
    I led a team of 6 in designing and developing custom software for HTX, aimed at assisting Home Team departments in 
    determining a suspect's familiarity with specific objects through eye-tracking technology. <br /><br />

    The goal was to create a deployable, non-invasive solution to improve investigative accuracy and operational efficiency.
  </p>

  <!-- 3-Column Summary Grid -->
  <div class="grid grid-cols-1 md:grid-cols-3 gap-8 mt-8">
    <div>
      <h2 class="font-semibold text-lg text-blue-900 mb-2 tracking-[-0.02em]">Key results</h2>
      <ul class="list-disc list-inside text-gray-700 space-y-1 tracking-[-0.02em]">
        <li>Accuracy for object familiarity detection reached 70%</li>
        <li>Closed the gap of object familiarity research</li>
        <li>Provided seamless software for investigator's usage</li>
      </ul>
    </div>
    <div>
      <h2 class="font-semibold text-lg text-blue-900 mb-2 tracking-[-0.02em]">Role & Timeline</h2>
      <ul class="list-disc list-inside text-gray-700 space-y-1 tracking-[-0.02em]">
        <li>Team Leader, Data Analyst & Designer</li>
        <li>August 2024 – May 2025</li>
      </ul>
    </div>
    <div>
      <h2 class="font-semibold text-lg text-blue-900 mb-2 tracking-[-0.02em]">Methods</h2>
      <ul class="list-disc list-inside text-gray-700 space-y-1 tracking-[-0.02em]">
        <li>Stakeholder Analysis / User Research</li>
        <li>Data Collection / Research</li>
        <li>Prototyping / Iterative Testing </li>
      </ul>
    </div>
  </div>

  <!-- Introduction Section -->
<div id="introduction" class="mt-16">

  <!-- Spot-the-Difference Hook -->
  <h2 class="text-2xl font-semibold text-blue-900 mb-4 tracking-[-0.02em]">Spot-the-Difference Challenge</h2>

  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    To better understand the premise of our project, let’s begin with a short visual activity.
  </p>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    Below are two images placed side by side—one of a cannabis plant, the other of a coral reef.
    Take a few seconds to observe both.
  </p>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-6">
    Can you tell which one is the cannabis plant?
  </p>

  <!-- Side-by-Side Images -->
  <div class="flex flex-col md:flex-row gap-6 justify-center items-center mb-6">
    <img src="assets/coral reef.jpg" alt="Visual Option 1" class="standard-img" />
    <img src="assets/cannabis.jpg" alt="Visual Option 2"class="standard-img" />
  </div>

  <!-- Reveal Answer -->
<div class="flex flex-col items-center">
  <button
  id="reveal-button"
    class="mb-2 px-6 py-2 bg-blue-900 text-white rounded-md hover:bg-blue-800 transition-colors duration-300"
  >
    Reveal Answer
  </button>

  <!-- Hidden Answer -->
  <p
    id="answer-text"
    class="mb-2 text-lg text-blue-900 font-medium hidden mt-4 tracking-[-0.02em]"
  >
    Answer: The right image is the cannabis plant
  </p>

  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    Suspects with prior exposure to cannabis tend to recognize it faster—even when it’s embedded in complex or unfamiliar visuals. Their attention often shifts to it instinctively, before they’re consciously aware  </p>
  
  <!-- Problem Statement -->
  <div class="mt-16">
    <h2 class="text-2xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Problem Statement</h2>
  
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      This instinctive recognition forms the foundation of our investigative question:
    </p>
  
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      <strong>How might we detect object familiarity in suspects during investigations—without their awareness?</strong>
    </p>
  
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      To guide our solution, we adopted the Double Diamond framework from Design Thinking, enabling us to explore the problem space broadly before zeroing in on a focused, effective solution.
    </p>
  
    <!-- Double Diamond Image -->
    <div class="flex justify-center my-6">
      <img src="assets/design thinking methodology.png" alt="Double Diamond Framework" class="standard-img"/>
    </div>
  
    <!-- Image Caption -->
    <p class="text-sm text-center text-gray-500 mt-2 tracking-[-0.02em] italic">
      Figure: Double Diamond Design Thinking Framework
    </p>
  
    <!-- Follow-up -->
    <div class="mt-6 space-y-2 text-lg tracking-[-0.02em] text-gray-700">
      <p><strong style="color:#d41c3c">Discover:</strong> Deep insights from stakeholder interviews and research.</p>
      <p><strong style="color:#fbac1c">Define:</strong> Identification of key operational challenges.</p>
      <p><strong style="color:#6fbe44">Develop:</strong> Brainstorming and evaluation of multiple potential solutions.</p>
      <p><strong style="color:#2cace4">Deliver:</strong> Refining and selecting the most promising approach—eye-tracking technology.</p>
    </div>
  </div>
  
  <!-- Discovery Section -->
  <div id="discovery" class="mt-16">
    <h2 class="text-2xl font-semibold text-blue-900 mb-6 tracking-[-0.02em]">Discovery</h2>
    
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      With our problem clearly defined, we moved into the discovery phase to gather insights from real-world investigative scenarios.
    </p>
  
    <!-- User Interviews -->
    <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">User Interviews</h3>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      We interviewed key stakeholders—including HTX representatives and investigators—to ensure our solution addressed real-world constraints.
    </p>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      Participants, selected for their familiarity with investigative workflows, shared pain points and expectations for a contactless familiarity detection tool.
    </p>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      Our discussions centered on:
    </p>
    <ul class="list-disc list-inside text-gray-700 text-lg tracking-[-0.02em] mb-8 space-y-2">
      <li>Current methods for evaluating a subject’s familiarity or intent.</li>
      <li>Limitations of tools that require physical contact or explicit cooperation.</li>
      <li>Scenarios where a passive familiarity tool would be most valuable.</li>
    </ul>

    <div class="flex justify-center my-6">
      <img src="assets\SUTDetect Finding from user interviews.png" alt="User Journey Mapping Diagram" class="standard-img" />
    </div>
  
    <!-- User Journey Mapping -->
    <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">User Journey Mapping</h3>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      Next, we mapped the investigative workflow to pinpoint friction points and moments where rapid, discreet detection is critical.
    </p>
    <ul class="list-disc list-inside text-gray-700 text-lg tracking-[-0.02em] mb-6 space-y-2">
      <li>Operational bottlenecks.</li>
      <li>Emotional and cognitive load during high-pressure scenarios.</li>
      <li>Critical stages for quick familiarity detection.</li>
    </ul>
    <!-- User Journey Mapping Image -->
    <div class="flex justify-center my-6">
      <img src="assets/SUTDetect - User Journey.png" alt="User Journey Mapping Diagram" class="standard-img" />
    </div>
    <p class="text-sm text-center text-gray-500 mt-2 tracking-[-0.02em] italic">
      User Journey Mapping
    </p>
  
    <!-- Identified Opportunities -->
    <h3 class="text-xl font-semibold text-blue-900 mb-4 tracking-[-0.02em] mt-10">Identified Opportunities</h3>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      Our research revealed several key themes that directly informed our design criteria:
    </p>
    <ul class="list-disc list-inside text-gray-700 text-lg tracking-[-0.02em] space-y-2 mb-8">
      <li><strong>Ease of Use:</strong> Intuitive interfaces requiring minimal training.</li>
      <li><strong>Discreet Operation:</strong> Functionality without physical contact, verbal prompts, or subject cooperation.</li>
      <li><strong>Frictionless Deployment:</strong> Rapid and practical deployment in time-sensitive environments.</li>
    </ul>
  
    <!-- Transition to Evaluating Existing Methods -->
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      With these insights in hand, we then evaluated existing methods to identify gaps in current investigative tools.
    </p>
  
    <!-- Evaluating Existing Methods -->
    <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Evaluating Existing Methods</h3>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      We compared traditional methods like polygraphs—which require physical sensors and controlled conditions—with emerging, contactless technologies.
    </p>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      While polygraphs are intrusive and limited in fast-paced environments, methods such as facial analysis and voice stress detection, though less burdensome, can be consciously manipulated.
    </p>
    <!-- Comparison: Polygraph vs. Contactless -->
<div class="flex flex-col md:flex-row justify-center items-center gap-8 my-6">

  <!-- Polygraph (Contact-Based) -->
  <div class="text-center">
    <img src="assets/Lie-Detector-Test.jpg" alt="Polygraph Machine" class="standard-img mb-2" />
    <p class="text-sm text-gray-500 italic tracking-[-0.02em]">Contact-Based: Traditional Polygraph Machine</p>
  </div>

  <!-- Contactless (Modern) -->
  <div class="text-center">
    <img src="assets/contactless.png" alt="Contactless Technology" class="standard-img mb-2" />
    <p class="text-sm text-gray-500 italic tracking-[-0.02em]">Contactless: Eye tracking technology</p>
  </div>

</div>

<!-- Contextual Summary -->
<p class="text-gray-700 text-lg tracking-[-0.02em] mb-8">
  This comparison reinforced our focus on developing a passive and reliable contactless solution—eliminating the need for physical interaction while improving accuracy in real-world settings.
</p>
  
    <!-- Our Objective -->
    <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Our Objective</h3>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-6">
      We aimed to develop a contactless software solution that passively detects object familiarity—without requiring physical contact, verbal prompts, or subject cooperation—while providing clear, actionable outputs.
    Hence, we decided to choose eye-tracking technology. 
    </p>
  
    <!-- Why Eye-Tracking -->
    <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Why Eye-Tracking</h3>
    <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
      Eye-tracking captures rapid, involuntary movements (fixations, saccades, and pupil dilation) within milliseconds, making it a reliable indicator of recognition.
    </p>
    <p class="text-gray-700 text-lg tracking-[-0.02em]">
      This system aligns perfectly with investigative needs for discretion, reliability, and rapid deployment.
    </p>
  </div>  

      <!-- MVP -->
      <div id="mvp">
        <!-- Defining Core Functionality -->
<div class="mt-16">
  <h2 class="text-2xl font-semibold text-blue-900 mb-4 tracking-[-0.02em]">The MVP (Minimum Viable Product) </h2>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    For our MVP, we prioritized several key functionalities to ensure the system meets real-world investigative needs:
  </p>
  <ul class="list-disc list-inside text-gray-700 text-lg tracking-[-0.02em] mb-8 space-y-2">
    <li><strong>Real-Time Eye-Tracking:</strong> Integrating robust algorithms with pre-existing Tobii external software and hardware to capture and analyze subtle eye movements—such as fixations, saccades, and pupil dilation—as subjects view different objects.</li>
    <li><strong>Machine Learning Analysis:</strong> Using a Random Forest model to process raw eye-tracking data and output whether a subject is familiar with an object.</li>
    <li><strong>User-Friendly Interface:</strong> Designing an intuitive dashboard that presents visual data in a clear and actionable format for investigators.</li>
    <li><strong>Real World = System (Nielsen Heuristics):</strong> Aligning system design with real-world investigative scenarios, adhering to Nielsen's principles for usability and natural user experience.</li>
  </ul>
</div>

<!-- Interactive Prototype -->
<div class="mt-16">
  <h2 class="text-2xl font-semibold text-blue-900 mb-4 tracking-[-0.02em]">Interactive Prototype</h2>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    I developed an interactive prototype to simulate the system’s functionality. This prototype allowed stakeholders to:
  </p>
  <ul class="list-disc list-inside text-gray-700 text-lg tracking-[-0.02em] mb-8 space-y-2">
    <li>Understand the entire system flow from login to results.</li>
    <li>Visualize the end product and identify features for further iterations.</li>
    <li>Provide valuable feedback on usability, accuracy, and overall integration into investigative workflows.</li>
    <li>Tweak the workflow to reflect actual real-world conditions.</li>
  </ul>
</div>

<!-- Interface Screens -->
<div class="mt-16">
  <h2 class="text-2xl font-semibold text-blue-900 mb-4 tracking-[-0.02em]">Interface Screens</h2>
  
  <!-- Login Page -->
  <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Login Page</h3>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    A secure and straightforward entry point for users to access the system.
  </p>
  <div class="flex justify-center my-4">
    <img src="assets/SUTDetect Webpage.png" alt="Login Page Screenshot" class="standard-img" />
  </div>

  <!-- Home Page -->
  <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Home Page</h3>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    The central hub where users can navigate through cases. Investigators can also download PDF reports with in-depth statistical outcomes and toggle views between incomplete and complete participants.
  </p>
  <div class="flex justify-center my-4">
    <img src="assets\New main page.png" alt="Home Page Screenshot" class="standard-img" />
  </div>

  <!-- Upload Image Screen -->
  <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Upload Image Screen</h3>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    Investigators can upload images of specific objects from crime scenes. A preview page allows them to verify image quality (ensuring images are not pixelated) before administering the test.
  </p>
  <div class="flex justify-center my-4">
    <img src="assets\New Upload Page 2nd.png" alt="Upload Image Screen" class="standard-img" />
  </div>
  <div class="flex justify-center my-4">
    <img src="assets\New Preview Page.png" alt="Upload Image Screen" class="standard-img" />
  </div>

  <!-- Dashboard Screen -->
  <h3 class="text-xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Dashboard Screen</h3>
  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    Once the test is completed, the dashboard displays results and key metrics, providing clear, actionable insights for investigators.
  </p>
  <div class="flex justify-center my-4">
    <img src="assets/New Dashboard.png" alt="Dashboard Screenshot" class="standard-img" />
  </div>
</div>

     <!-- Impact -->
<div id="impact" class="mt-16">
  <h2 class="text-2xl font-semibold text-blue-900 mb-4 tracking-[-0.02em]">Impact</h2>

  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    SUTDetect introduced a novel, contactless method to help investigators determine a suspect’s familiarity with objects—without requiring interaction or cooperation. 
  </p>

  <p class="text-gray-700 text-lg tracking-[-0.02em] mb-4">
    By combining eye-tracking with a simple and intuitive interface, we delivered a functional system that aligned with real-world investigative needs: speed, discretion, and usability.
  </p>

  <p class="text-gray-700 text-lg tracking-[-0.02em]">
    The project bridged a research gap and laid the groundwork for future applications in law enforcement and national security—offering a fresh way to interpret instinctive human behaviour for operational insights.
  </p>
</div>

      <!-- Next Steps -->
<div id="learnings" class="mt-16">
  <h2 class="text-2xl font-semibold text-blue-900 mb-2 tracking-[-0.02em]">Next Steps</h2>
  <p class="text-gray-700 text-lg tracking-[-0.02em]">
    The project is currently in the software development phase. We are building a functional prototype that integrates with 
    <strong>Tobii eye-tracking hardware</strong> using GUI automation to record and process eye movement data during object exposure.
  </p>

  <p class="text-gray-700 text-lg tracking-[-0.02em] mt-4">
    A <strong>Random Forest classification model</strong> is being trained to detect object familiarity based on collected visual attention patterns. 
    This model uses features such as fixation duration, gaze entropy, and scanpath variance to determine whether a subject is likely familiar with a given object.
  </p>

  <p class="text-gray-700 text-lg tracking-[-0.02em] mt-4">
    The final integration and interface will allow investigators to run controlled tests and receive an interpretable output without requiring technical intervention. 
    Completion is expected by <strong>May 2025</strong>.
  </p>
</div>


      <!-- More Case Studies and Writings -->
<div class="mt-20">
  <h2 class="text-2xl font-semibold text-blue-900 mb-6 tracking-[-0.02em]">✴ More case studies and writings</h2>
  <hr class="border-t border-gray-200 mb-10" />

  <div class="grid grid-cols-1 md:grid-cols-3 gap-8">

    <!-- Case Study 1 -->
    <a href="contractbook-pdf.html" class="group block bg-white border border-gray-200 rounded-lg overflow-hidden shadow-sm hover:shadow-md transition-shadow duration-300">
      <img src="assets/Contractbook PDF.png" alt="Contractbook PDF Signing" class="w-full h-48 object-cover" />
      <div class="p-4">
        <h3 class="text-lg font-semibold text-gray-900 mb-1 group-hover:text-blue-900 transition-colors">Contractbook ・ PDF Signing</h3>
        <p class="text-gray-600 text-sm">Help users improve PDF signing by adding more freedom and control over signature placement.</p>
      </div>
    </a>

    <!-- Case Study 2 -->
    <a href="usability-testing.html" class="group block bg-white border border-gray-200 rounded-lg overflow-hidden shadow-sm hover:shadow-md transition-shadow duration-300">
      <img src="assets/usability-testing-thumbnail.png" alt="Usability Testing" class="w-full h-48 object-cover" />
      <div class="p-4">
        <h3 class="text-lg font-semibold text-gray-900 mb-1 group-hover:text-blue-900 transition-colors">How I’ve Self-Taught and Executed Usability Testing?</h3>
        <p class="text-gray-600 text-sm">Learn how I moved from zero knowledge to running real usability tests with confidence.</p>
      </div>
    </a>

    <!-- Case Study 3 -->
    <a href="job-hunt-journey.html" class="group block bg-white border border-gray-200 rounded-lg overflow-hidden shadow-sm hover:shadow-md transition-shadow duration-300">
      <img src="assets/6-month-jobhunt.png" alt="Job Hunt Journey" class="w-full h-48 object-cover" />
      <div class="p-4">
        <h3 class="text-lg font-semibold text-gray-900 mb-1 group-hover:text-blue-900 transition-colors">My 6-Month Tech Job Hunt Journey</h3>
        <p class="text-gray-600 text-sm">A transparent look into applications, interviews, rejections, and the lessons I learned.</p>
      </div>
    </a>

  </div>
</div>

    </section>
  </div>
</div>

  <script src="./sutdetect_motion.js"></script>
</body>
</html>


